{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T19:55:43.371567Z",
     "start_time": "2019-10-13T19:55:43.191459Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import geopy\n",
    "from geopy.distance import distance\n",
    "from geopy.distance import VincentyDistance\n",
    "import json\n",
    "from datetime import date, datetime, timedelta\n",
    "import datetime as dt\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To get JSON data of historical weather data of the cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring all required variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T16:41:14.168678Z",
     "start_time": "2019-10-13T16:41:14.165419Z"
    }
   },
   "outputs": [],
   "source": [
    "x = 1567321200 #UNIX time value of 9/1/2019. \n",
    "centroids = [(38.90257, -77.03449), (48.85154, 2.34756), (33.4574, -111.92756), (34.05305, -118.24641)] #Centroids of the 49 sq. mile square of the city\n",
    "z=0 #Each z value are increase points to the next city in the centroids list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get weather data of one city for the month of September"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T16:41:16.833983Z",
     "start_time": "2019-10-13T16:41:16.824118Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_json(coors,time):\n",
    "    global z\n",
    "    global column\n",
    "    for i in range(1,31):\n",
    "        URL_get = f\"https://api.darksky.net/forecast/4055c5211186d74c8a050a2b2cccea87/{coors[0]},{coors[1]},{time}?exclude=currently,flags,minutely,alerts\"\n",
    "        rget = requests.get(URL_get)\n",
    "        json_data = rget.json()\n",
    "        #To convert it to a dataframe\n",
    "        df = pd.DataFrame.from_dict(json_data['daily']['data'], orient = 'columns')\n",
    "        column = ['apparentTemperatureHigh', 'apparentTemperatureHighTime', 'apparentTemperatureLow', 'apparentTemperatureLowTime', 'apparentTemperatureMax', 'apparentTemperatureMaxTime', 'apparentTemperatureMin', 'apparentTemperatureMinTime', 'city', 'cloudCover', 'dewPoint', 'humidity', 'icon', 'moonPhase', 'ozone', 'precipIntensity', 'precipIntensityMax', 'precipIntensityMaxTime', 'precipProbability', 'precipType', 'pressure', 'summary', 'sunriseTime', 'sunsetTime', 'temperatureHigh', 'temperatureHighTime', 'temperatureLow', 'temperatureLowTime', 'temperatureMax', 'temperatureMaxTime', 'temperatureMin', 'temperatureMinTime', 'time', 'uvIndex', 'uvIndexTime', 'visibility', 'windBearing', 'windGust', 'windGustTime', 'windSpeed']\n",
    "        df = df.reindex(sorted(column), axis=1)\n",
    "        #Appending to CSV\n",
    "        if z==0:\n",
    "            df['city']='WashingtonDC'\n",
    "            if i==1:\n",
    "                df.to_csv(r'/Users/himanshuagarwal/BirdProject/ExternalDataSources/WeatherData/DailyWeather.csv', index = None, mode = 'a', header=True) #Don't forget to add '.csv' at the end of the path\n",
    "            else:\n",
    "                df.to_csv(r'/Users/himanshuagarwal/BirdProject/ExternalDataSources/WeatherData/DailyWeather.csv', index = None, mode = 'a', header=False) #Don't forget to add '.csv' at the end of the path\n",
    "        elif z==1:\n",
    "            df['city']='Paris'\n",
    "            df.to_csv(r'/Users/himanshuagarwal/BirdProject/ExternalDataSources/WeatherData/DailyWeather.csv', index = None, mode = 'a', header=False) #Don't forget to add '.csv' at the end of the path\n",
    "        elif z==2:\n",
    "            df['city']='AZ'\n",
    "            df.to_csv(r'/Users/himanshuagarwal/BirdProject/ExternalDataSources/WeatherData/DailyWeather.csv', index = None, mode = 'a', header=False) #Don't forget to add '.csv' at the end of the path\n",
    "        else:\n",
    "            df['city']='LA'\n",
    "            df.to_csv(r'/Users/himanshuagarwal/BirdProject/ExternalDataSources/WeatherData/DailyWeather.csv', index = None, mode = 'a', header=False) #Don't forget to add '.csv' at the end of the path\n",
    "        #Increasing time component to capture weather for entire month for the city\n",
    "        time = time + 86400\n",
    "    z = z+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping over the centroids of the four cities to pass it to above function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T16:41:42.989590Z",
     "start_time": "2019-10-13T16:41:19.742612Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "z = 0 #Each z value are increase points to the next city in the centroids list\n",
    "for i,n in enumerate(centroids):\n",
    "    get_json(n,x)\n",
    "    x=x+86400 # 86,400 seconds between two dates for same timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing metro stations data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T16:38:19.239031Z",
     "start_time": "2019-10-05T16:38:19.236055Z"
    }
   },
   "outputs": [],
   "source": [
    "#List of cities that are part of my project. The '+' symbol is because it would go into a URL\n",
    "cities = ['Washington+DC','Paris','Los+Angeles','Phoenix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T18:30:46.813247Z",
     "start_time": "2019-10-05T18:30:43.012558Z"
    }
   },
   "outputs": [],
   "source": [
    "for n in cities:\n",
    "    URLmet = f\"https://maps.googleapis.com/maps/api/place/textsearch/json?query=metro+stations+in+{n}&fields=formatted_address,name,geometry,id&locationbias=circle:9000@38.90257,-77.03449&key=AIzaSyDsWngN6Fn0rVOMClQqE21kkmhEG_z0vgM\"\n",
    "    rgetmet = requests.get(URLmet)\n",
    "    jsonmet = rgetmet.json()\n",
    "    #The data is within the 'results' dictionary in the json\n",
    "    df = pd.DataFrame.from_dict(jsonmet['results'], orient = 'columns')\n",
    "    #There is column called 'opening hours' which tells if the metro is open or not at the time of the API call..\n",
    "    #..That column isn't returned every time , so in order to have more consistency and also it not being part \n",
    "    #..of the analysis, removed.\n",
    "    if 'opening_hours' in df.columns:\n",
    "        df = df.drop(['opening_hours'],axis=1)\n",
    "    a = list(jsonmet.keys())\n",
    "    jsonmetx = jsonmet\n",
    "    #Google Place API on number of API calls per second. Hence added the sleep timer.\n",
    "    time.sleep(10)\n",
    "    #Maximum number of results returned at a time is 20. If there are more to be returned, they will have a.. \n",
    "    #..'next_page_token' key-value pair in the json. The below code checks for it and calls API to retrieve..\n",
    "    #..subsequent information\n",
    "    while 'next_page_token' in a:\n",
    "        URLmetx = f\"https://maps.googleapis.com/maps/api/place/textsearch/json?pagetoken={jsonmetx['next_page_token']}&key=AIzaSyDsWngN6Fn0rVOMClQqE21kkmhEG_z0vgM\"\n",
    "        rgetmetx = requests.get(URLmetx)\n",
    "        jsonmetx = rgetmetx.json()\n",
    "        df2 = pd.DataFrame.from_dict(jsonmetx['results'], orient = 'columns')\n",
    "        if 'opening_hours' in df2.columns:\n",
    "            df2 = df2.drop(['opening_hours'],axis=1)\n",
    "        df = df.append(df2,ignore_index=True, sort=True)\n",
    "        a = list(jsonmetx.keys())\n",
    "        time.sleep(10)\n",
    "    else:\n",
    "        #1. Adding the city coulmn for entering value of the respective city the metro station belongs to.\n",
    "        #2. Exporting to a CSV file.\n",
    "        df['city'] = n\n",
    "        df.to_csv(r'/Users/himanshuagarwal/BirdProject/ExternalDataSources/MetroData/MetroStations.csv', index = None, mode = 'a', header=True)\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gettting attractions in and around the cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-06T18:55:51.234526Z",
     "start_time": "2019-10-06T18:52:49.779068Z"
    }
   },
   "outputs": [],
   "source": [
    "for n in cities:\n",
    "    URLmet = f\"https://maps.googleapis.com/maps/api/place/textsearch/json?query=attractions+near+{n}&fields=formatted_address,name,geometry,id&key=AIzaSyDsWngN6Fn0rVOMClQqE21kkmhEG_z0vgM\"\n",
    "    rgetmet = requests.get(URLmet)\n",
    "    jsonmet = rgetmet.json()\n",
    "    #The data is within the 'results' dictionary in the json\n",
    "    df = pd.DataFrame.from_dict(jsonmet['results'], orient = 'columns')\n",
    "    #There is column called 'opening hours' which tells if the metro is open or not at the time of the API call..\n",
    "    #..That column isn't returned every time , so in order to have more consistency and also it not being part \n",
    "    #..of the analysis, removed.\n",
    "    if 'opening_hours' in df.columns:\n",
    "        df = df.drop(['opening_hours'],axis=1)\n",
    "    a = list(jsonmet.keys())\n",
    "    jsonmetx = jsonmet\n",
    "    #Google Place API on number of API calls per second. Hence added the sleep timer.\n",
    "    time.sleep(10)\n",
    "    #Maximum number of results returned at a time is 20. If there are more to be returned, they will have a.. \n",
    "    #..'next_page_token' key-value pair in the json. The below code checks for it and calls API to retrieve..\n",
    "    #..subsequent information\n",
    "    while 'next_page_token' in a:\n",
    "        URLmetx = f\"https://maps.googleapis.com/maps/api/place/textsearch/json?pagetoken={jsonmetx['next_page_token']}&key=AIzaSyDsWngN6Fn0rVOMClQqE21kkmhEG_z0vgM\"\n",
    "        rgetmetx = requests.get(URLmetx)\n",
    "        jsonmetx = rgetmetx.json()\n",
    "        df2 = pd.DataFrame.from_dict(jsonmetx['results'], orient = 'columns')\n",
    "        if 'opening_hours' in df2.columns:\n",
    "            df2 = df2.drop(['opening_hours'],axis=1)\n",
    "        df = df.append(df2,ignore_index=True, sort=True)\n",
    "        a = list(jsonmetx.keys())\n",
    "        time.sleep(10)\n",
    "    else:\n",
    "        #1. Adding the city coulmn for entering value of the respective city the metro station belongs to.\n",
    "        #2. Exporting to a CSV file.\n",
    "        df['city'] = n\n",
    "        df.to_csv(r'/Users/himanshuagarwal/BirdProject/ExternalDataSources/Attractions/Attractions.csv', index = None, mode = 'a', header=True)\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting data to PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Scooters data for DC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T19:59:45.033495Z",
     "start_time": "2019-10-13T19:59:45.023544Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imported in the top of the notebook along with other imported libraries\n",
    "\"\"\"\n",
    "from sqlalchemy import create_engine   #To create a connection to the PostgreSQL db. \n",
    "import pandas as pd\n",
    "import os                              #To get pathnames of the Bird Scooters from local computer\n",
    "import glob                            #To get filenames from the BirdProject folder\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To create a connection with the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T20:06:39.972182Z",
     "start_time": "2019-10-13T20:06:39.919623Z"
    }
   },
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://himanshuagarwal:@localhost/scooterapi')\n",
    "#Syntax: create_engine('postgresql://username:password@localhost/db_name')\n",
    "#username: himanshuagarwal\n",
    "#password: 'No password set up'\n",
    "#db_name: scooterapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To generate a list of all the filenames containing the Bird scooters information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T20:07:04.498057Z",
     "start_time": "2019-10-13T20:07:04.492710Z"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/himanshuagarwal/BirdProject/Prev_Data_collected\")\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "all_filenames = sorted(all_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entering data to SQL after some data cleaning/manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T20:20:39.589833Z",
     "start_time": "2019-10-13T20:16:00.898780Z"
    }
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 12 fields in line 27458, saw 13\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-c1f0cb0e59b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_filenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcolsss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Origin_Dist'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'area_key'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'battery_level'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bounty_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'captive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'code'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimated_range'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latitude'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'longitude'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nest_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vehicle_class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{i}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbattery_level\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"battery_level\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbattery_level\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"battery_level\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mentproject/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mentproject/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mentproject/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mentproject/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2046\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2047\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2048\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2049\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2050\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 12 fields in line 27458, saw 13\n"
     ]
    }
   ],
   "source": [
    "for i in all_filenames:\n",
    "    colsss = ['Date', 'Origin_Dist', 'Time', 'area_key', 'battery_level', 'bounty_id', 'captive', 'code', 'estimated_range', 'id', 'latitude', 'longitude', 'model', 'nest_id', 'vehicle_class']\n",
    "    df = pd.read_csv(f'{i}')\n",
    "    df = df.reindex(sorted(colsss), axis=1)\n",
    "    if True in df.battery_level.astype(str).str.contains(\"battery_level\"):\n",
    "        df = df[~df.battery_level.astype(str).str.contains(\"battery_level\")]\n",
    "    df.to_sql('birds_dc', engine,if_exists='append')\n",
    "\n",
    "#colsss: All column names present in scooter data\n",
    "# \n",
    "#if True in df.battery_level.astype(str).str.contains(\"battery_level\"):\n",
    "#        df = df[~df.battery_level.astype(str).str.contains(\"battery_level\")]\n",
    "#(This code above checks for rows that have headers and removes it)\n",
    "#\n",
    "#df = df.reindex(sorted(colsss), axis=1)\n",
    "#(When the API doesnt return all columns, this code adds the missing column and inputs an empty value for it. This \n",
    "# ....way the data is consistent throughout)\n",
    "#\n",
    "#df.to_sql('birds_dc', engine,if_exists='append')\n",
    "#(This code above, enters the data into a database named 'birds_dc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 366,
   "position": {
    "height": "40px",
    "left": "743px",
    "right": "20px",
    "top": "27px",
    "width": "489px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
